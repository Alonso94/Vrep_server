{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.env_sim import rozum_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    }
   ],
   "source": [
    "env=rozum_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# fourcc=cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out=cv2.VideoWriter('output.mp4',fourcc,15.0,(1024,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# from tensorflow.python.util import deprecation\n",
    "# deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "# # for i in range(100):\n",
    "# #         a=env.sample_action()\n",
    "# #         print(a)\n",
    "# #         img,_,_,_=env.step(a)\n",
    "# #         img=env.render()\n",
    "# #         out.write(img)\n",
    "# # #         rgb=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "# # #         plt.imshow(np.array(rgb))\n",
    "# # #         plt.show()\n",
    "# # out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines.common.policies import CnnPolicy\n",
    "# from stable_baselines.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines import PPO2\n",
    " \n",
    "# print(\"before training\")\n",
    "# for i in range(50):\n",
    "#     action=env.sample_action()\n",
    "#     obs, rewards, dones, info = env.step(action)\n",
    "#     print(rewards)\n",
    "\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# model = PPO2(CnnPolicy, env, verbose=2,tensorboard_log='./PPO2_rozum')\n",
    "# print(\"start learning\")\n",
    "# model.learn(total_timesteps=10000,tb_log_name=\"first_part\")\n",
    "\n",
    "# print(\"after training\")\n",
    "# obs = env.reset()\n",
    "# for i in range(50):\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, dones, info = env.step(action)\n",
    "#     print(rewards)\n",
    "# model.save('PPO_rozum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --port=6007 --logdir='./PPO2_rozum/first_part'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines.common.policies import CnnPolicy\n",
    "# from stable_baselines.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines import PPO2\n",
    " \n",
    "# print(\"before training\")\n",
    "# # for i in range(50):\n",
    "# #     action=env.sample_action()\n",
    "# #     obs, rewards, dones, info = env.step(action)\n",
    "# #     print(rewards)\n",
    "\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "# env.reset()\n",
    "# model = PPO2(CnnPolicy, env, verbose=2,tensorboard_log='./PPO2_rozum')\n",
    "# # print(\"start learning\")\n",
    "# # model.learn(total_timesteps=10000,tb_log_name=\"first_part\")\n",
    "# model=PPO2.load(\"PPO_rozum\",env=env)\n",
    "# print(\"after training\")\n",
    "# obs = env.reset()\n",
    "# for i in range(50):\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, dones, info = env.step(action)\n",
    "#     print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import CnnPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "# env = gym.make('Pendulum-v0')\n",
    "\n",
    "model = SAC(CnnPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=50000, log_interval=100)\n",
    "model.save(\"sac_rozum\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC.load(\"sac_rozum\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "#     env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
